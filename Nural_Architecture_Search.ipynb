{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaBQSkv6aeeZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torch.optim as optim\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnQ886g9DBCd"
      },
      "outputs": [],
      "source": [
        "train_dataset = torchvision.datasets.MNIST(root = './data', train = True, transform = torchvision.transforms.ToTensor(), download = True)\n",
        "test_dataset = torchvision.datasets.MNIST(root = './data', train = False, transform = torchvision.transforms.ToTensor(), download = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZvDIGIZsidt"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(dataset = train_dataset, batch_size = 32, shuffle = True)\n",
        "test_loader = DataLoader(dataset = test_dataset, batch_size = 32, shuffle = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGe1VBVow0z6"
      },
      "outputs": [],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "M0dd5rQkw9IN"
      },
      "outputs": [],
      "source": [
        "train_images = torch.stack([image for image, label in train_dataset])  # Shape: [60000, 1, 28, 28]\n",
        "train_labels = torch.tensor([label for image, label in train_dataset]) # Shape: [60000]\n",
        "\n",
        "test_images = torch.stack([image for image, label in test_dataset])    # Shape: [10000, 1, 28, 28]\n",
        "test_labels = torch.tensor([label for image, label in test_dataset])   # Shape: [10000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0Ix7Pxi0xTfx",
        "outputId": "7face361-d691-4b2d-ab12-db3ce8b2f30e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([60000, 1, 28, 28])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nw51zBnJxbgO",
        "outputId": "ae1a37d3-bdd3-42aa-ffa8-e1ea1959efbb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([60000])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XYi0DV9t09T1",
        "outputId": "ebbd7fe2-2a80-4de7-dfa5-1ac454bddc56"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10000, 1, 28, 28])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pvC-zTiozLnA"
      },
      "outputs": [],
      "source": [
        "mean_train = train_images.view(60000, -1).mean(dim = 1, keepdim = True)\n",
        "std_train  = train_images.view(60000, -1).std(dim = 1, keepdim = True)\n",
        "mean_test = test_images.view(10000, -1).mean(dim = 1, keepdim = True)\n",
        "std_test  = test_images.view(10000, -1).std(dim = 1, keepdim = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "43Z3UQho0GwK"
      },
      "outputs": [],
      "source": [
        "train_images_normalized = (train_images.view(60000,-1) - mean_train)/std_train\n",
        "test_images_normalized = (test_images.view(10000,-1) - mean_test)/std_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QpUYQMcn0HrQ"
      },
      "outputs": [],
      "source": [
        "train_images_normalized = train_images_normalized.view(60000,28,28)\n",
        "test_images_normalized = test_images_normalized.view(10000,28,28)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_oFcbQixw-eh"
      },
      "outputs": [],
      "source": [
        "filter_height = torch.tensor([1, 3, 5, 7])\n",
        "filter_width = torch.tensor([1, 3, 5, 7])\n",
        "num_of_filters = torch.tensor([4, 8, 16, 32])\n",
        "search_space = torch.stack([filter_height,filter_width,num_of_filters], dim = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lTZs3BpfrxmE",
        "outputId": "38a95dc6-c8f3-48d8-914d-e9c371aeb0f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filter_height.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8j4WhISkMbGY",
        "outputId": "95ace8dc-6126-4e55-d526-46d31d13dfb1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1,  3,  5,  7],\n",
              "        [ 1,  3,  5,  7],\n",
              "        [ 4,  8, 16, 32]])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "search_space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2TddVTDm04LB"
      },
      "outputs": [],
      "source": [
        "batch_size_RNN = 1\n",
        "input_size = 1\n",
        "seq_len = 12\n",
        "num_layers = 3\n",
        "num_attribute = 4\n",
        "num_layers_attributes = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6VZN7rZFlD_0"
      },
      "outputs": [],
      "source": [
        "class ControllerRNN(nn.Module):\n",
        "  def __init__(self, input_size = 1, hidden_size = 32):\n",
        "    super().__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.rnn = nn.RNNCell(input_size, hidden_size)\n",
        "    self.logits = nn.Linear(hidden_size, 4)\n",
        "    self.W_prev = torch.randn(hidden_size, hidden_size)\n",
        "    self.W_curr = torch.randn(hidden_size, hidden_size)\n",
        "    self.v = torch.randn(hidden_size)\n",
        "\n",
        "\n",
        "  def forward(self):\n",
        "    x_t = torch.zeros(batch_size_RNN, input_size)\n",
        "    h_t = torch.ones(batch_size_RNN, self.hidden_size)\n",
        "    outputs = []\n",
        "    attention = []\n",
        "    skip_probs = []\n",
        "    max_probs = []\n",
        "    for i in range(num_layers):\n",
        "      for j in range(num_attribute):\n",
        "        if j == 3:\n",
        "          h_t = self.rnn(x_t,h_t)\n",
        "          attention.append(h_t)\n",
        "\n",
        "          if len(attention) > 1:\n",
        "            scores = []\n",
        "\n",
        "            for prev_h in attention[:-1]:  # all previous anchors\n",
        "                z = torch.tanh(prev_h @ self.W_prev + h_t @ self.W_curr)\n",
        "                scores.append(torch.sigmoid(torch.matmul(z, self.v)).item())\n",
        "\n",
        "            skip_probs.append(scores)\n",
        "\n",
        "        else:\n",
        "          h_t = self.rnn(x_t, h_t)\n",
        "          logits = self.logits(h_t)\n",
        "          prob = F.softmax(logits, dim = 1)\n",
        "          predicted_index = torch.argmax(prob, dim=1)\n",
        "          x_t = search_space[j][predicted_index].unsqueeze(1).float()\n",
        "          max_probs.append(torch.max(prob))\n",
        "          outputs.append(x_t.item())\n",
        "    return outputs, skip_probs, max_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ak6Pn_4wMEKl"
      },
      "outputs": [],
      "source": [
        "rnn = ControllerRNN()outputs,skip_probs, max_probs = rnn.forward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OYFBVevzOPEr",
        "outputId": "b78fc38c-a44a-44a1-98e7-8c77ff410f83"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.3250, grad_fn=<MaxBackward1>)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max_probs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hEbQDqe32KDX",
        "outputId": "9f258ced-81a5-4c3e-97f0-b60a0d998bd1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[0.9959191679954529], [0.9959294199943542, 0.9964578747749329]]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "skip_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wshMTzld9SF8"
      },
      "outputs": [],
      "source": [
        "outputs = [int(x) for x in outputs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "e2p_sDoWb-og",
        "outputId": "31d409e0-968b-4436-8f7e-5e1d51e4c7c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[3, 7, 32, 7, 7, 32, 7, 7, 32]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JQayjFXE4_fD"
      },
      "outputs": [],
      "source": [
        "class ChildNetwork(nn.Module):\n",
        "  def __init__(self, input_channels = 1,batch_size = 1, outputs = [] ,skip_prob = [] ):\n",
        "    super().__init__()\n",
        "    self.in_channel = input_channels\n",
        "    self.convs = nn.ModuleList()\n",
        "    self.linear = None\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "    for i in range(num_layers):\n",
        "        attributes = outputs[i*num_layers_attributes:(i+1)*num_layers_attributes]\n",
        "        out_channels = attributes[2]\n",
        "        kernel_height = attributes[0]\n",
        "        kernel_width = attributes[1]\n",
        "        conv = nn.Conv2d(\n",
        "            in_channels=self.in_channel,\n",
        "            out_channels=out_channels,\n",
        "            kernel_size=(kernel_height, kernel_width)\n",
        "        )\n",
        "        self.convs.append(conv)\n",
        "        if i < num_layers - 1:\n",
        "          prev_probs = skip_probs[i]\n",
        "          index = prev_probs.index(max(prev_probs))\n",
        "          self.in_channel = outputs[index*num_layers_attributes + (num_layers_attributes-1)]\n",
        "\n",
        "  def forward(self, x):\n",
        "    layer_outputs = []\n",
        "    non_used_layers = [1] + [0] * (num_layers - 1)\n",
        "    non_used_layers_outputs = []\n",
        "    for i, conv in enumerate(self.convs):\n",
        "        if i >0:\n",
        "          prev_probs = skip_probs[i-1]\n",
        "          index = prev_probs.index(max(prev_probs))\n",
        "          x = conv(layer_outputs[index])\n",
        "          non_used_layers[index] = 1\n",
        "        else:\n",
        "          x = F.relu(conv(x))\n",
        "        layer_outputs.append(x)\n",
        "    for i in range(len(non_used_layers)):\n",
        "      if non_used_layers[i] == 0:\n",
        "        non_used_layers_outputs.append(layer_outputs[i])\n",
        "\n",
        "    max_h = max([x.shape[2] for x in non_used_layers_outputs])\n",
        "    max_w = max([x.shape[3] for x in non_used_layers_outputs])\n",
        "\n",
        "    padded_outputs = []\n",
        "    for out in non_used_layers_outputs:\n",
        "        _, _, h, w = out.shape\n",
        "        pad_h = max_h - h\n",
        "        pad_w = max_w - w\n",
        "        # Pad (left, right, top, bottom)\n",
        "        padded = F.pad(out, (0, pad_w, 0, pad_h))\n",
        "        padded_outputs.append(padded)\n",
        "\n",
        "    combined = torch.cat(padded_outputs, dim=1)\n",
        "    flattened = combined.view(x.shape[0], -1)\n",
        "    if self.linear is None:\n",
        "        input_features = flattened.shape[1]\n",
        "        self.linear = nn.Linear(input_features, 10).to(flattened.device)\n",
        "    output = self.linear(flattened)\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SWkty6XMB45c"
      },
      "outputs": [],
      "source": [
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEln0a_DZlwe"
      },
      "outputs": [],
      "source": [
        "train_images_normalized = train_images_normalized.unsqueeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_S4QKud05dX_"
      },
      "outputs": [],
      "source": [
        "test_images_normalized = test_images_normalized.unsqueeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQTCjqWaeFjS"
      },
      "outputs": [],
      "source": [
        "def train_test(model, X_train, y_train, X_test, y_test, optimizer, criterion, batch_size = 32, epochs = 1000):\n",
        "  model.train()\n",
        "  for i in range(epochs):\n",
        "    total_loss = 0.0\n",
        "    idx = torch.randint(low = 0, high = X_train.shape[0]-batch_size, size = (batch_size,))\n",
        "    X_train_batch = X_train[idx]\n",
        "    y_train_batch = y_train[idx]\n",
        "    optimizer.zero_grad()\n",
        "    output = model(X_train_batch)\n",
        "    loss = criterion(output, y_train_batch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss += loss.item()\n",
        "\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    output = model(X_test)\n",
        "    _, predicted = torch.max(output, 1)\n",
        "    correct = (predicted == y_test).sum().item()\n",
        "    accuracy = correct / y_test.size(0)\n",
        "\n",
        "  return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wbG0aiCn57kT"
      },
      "outputs": [],
      "source": [
        "##Train loop\n",
        "controller_optimizer = optim.Adam(rnn.parameters(), lr = 0.01)\n",
        "num_epochs = 10\n",
        "for i in range(num_epochs):\n",
        "  loss = 0\n",
        "  for p in max_probs:\n",
        "    log_p = torch.log(p)\n",
        "    loss -= log_p * reward  # negative for gradient ascent\n",
        "\n",
        "loss.backward()\n",
        "controller_optimizer.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KL3Yt1DVdgX"
      },
      "outputs": [],
      "source": [
        "rnn = ControllerRNN()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gT0jCpHvVFT3",
        "outputId": "1d2b1b44-4e00-45ac-f28a-f516fe2769b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 177.1315, Best Acc: 0.8437\n",
            "Epoch 1, Loss: 147.3927, Best Acc: 0.9141\n",
            "Epoch 2, Loss: 90.9721, Best Acc: 0.9141\n",
            "Epoch 3, Loss: 53.5206, Best Acc: 0.9141\n",
            "Epoch 4, Loss: 31.8494, Best Acc: 0.9141\n",
            "Epoch 5, Loss: 19.8428, Best Acc: 0.9141\n",
            "Epoch 6, Loss: 12.4181, Best Acc: 0.9141\n",
            "Epoch 7, Loss: 7.7775, Best Acc: 0.9141\n",
            "Epoch 8, Loss: 4.9475, Best Acc: 0.9173\n",
            "Epoch 9, Loss: 3.2429, Best Acc: 0.9173\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 10\n",
        "final_batch_size = 20\n",
        "controller_optimizer = optim.Adam(rnn.parameters(), lr=0.01)\n",
        "\n",
        "best_accuracy = 0.0\n",
        "best_architecture = None\n",
        "best_skip_prob = None\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    controller_optimizer.zero_grad()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for j in range(final_batch_size):\n",
        "        outputs, skip_probs, max_probs = rnn.forward()\n",
        "        outputs = [int(x) for x in outputs]\n",
        "\n",
        "        # Build and train the child model\n",
        "        CN = ChildNetwork(outputs=outputs, skip_prob=skip_probs)\n",
        "        optimizer = optim.Adam(CN.parameters(), lr=0.01)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        accuracy = train_test(\n",
        "            CN, train_images_normalized, train_labels,\n",
        "            test_images_normalized, test_labels,\n",
        "            optimizer=optimizer, criterion=criterion,\n",
        "            batch_size=32, epochs=100\n",
        "        )\n",
        "\n",
        "        # Save best architecture based on accuracy\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            best_architecture = outputs\n",
        "            best_skip_prob = skip_probs  # if required\n",
        "\n",
        "        # REINFORCE loss\n",
        "        reward = torch.tensor(accuracy, dtype=torch.float32)\n",
        "        loss = 0\n",
        "        for p in max_probs:\n",
        "            log_p = torch.log(p + 1e-8)\n",
        "            loss -= log_p * reward\n",
        "        total_loss += loss\n",
        "\n",
        "    total_loss.backward()\n",
        "    controller_optimizer.step()\n",
        "    print(f'Epoch {epoch}, Loss: {total_loss.item():.4f}, Best Acc: {best_accuracy:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate or reuse the best architecture found\n",
        "print(\"Best architecture:\", best_architecture)\n",
        "\n",
        "# Build and train final child model more thoroughly\n",
        "CN = ChildNetwork(outputs=best_architecture, skip_prob=best_skip_prob)\n",
        "optimizer = optim.Adam(CN.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "final_accuracy = train_test(\n",
        "    CN, train_images_normalized, train_labels,\n",
        "    test_images_normalized, test_labels,\n",
        "    optimizer=optimizer, criterion=criterion,\n",
        "    batch_size=32, epochs=300  # train longer this time\n",
        ")\n",
        "\n",
        "print(f\"Final accuracy of best architecture: {final_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2YGdcAjYOpJ",
        "outputId": "78b4b6b2-cabb-4bdd-e9d5-af4d964f7583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best architecture: [5, 5, 16, 5, 5, 16, 5, 5, 16]\n",
            "Final accuracy of best architecture: 0.9202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wx2SBcKLbj2A",
        "outputId": "1a5a1625-c7a8-49c3-ab39-d2ea1d0bfd04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3, 1, 16, 1, 5, 4, 1, 5, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn.eval()\n",
        "num_samples = 30\n",
        "sampled_architectures = []\n",
        "\n",
        "for _ in range(num_samples):\n",
        "    outputs, skip_probs, max_probs = rnn.forward()\n",
        "    arch = {\n",
        "        'outputs': [int(x) for x in outputs],\n",
        "        'skip_probs': skip_probs,\n",
        "        'max_probs': max_probs\n",
        "    }\n",
        "    sampled_architectures.append(arch)\n"
      ],
      "metadata": {
        "id": "uW3noiM5b2zK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = []\n",
        "\n",
        "for arch in sampled_architectures:\n",
        "    CN = ChildNetwork(outputs=arch['outputs'], skip_prob=arch['skip_probs'])\n",
        "    optimizer = optim.Adam(CN.parameters(), lr=0.01)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    acc = train_test(\n",
        "        CN, train_images_normalized, train_labels,\n",
        "        test_images_normalized, test_labels,\n",
        "        optimizer=optimizer, criterion=criterion,\n",
        "        batch_size=32, epochs=20  # Shorter training for speed\n",
        "    )\n",
        "    accuracies.append(acc)\n"
      ],
      "metadata": {
        "id": "YNUuS33Zj89e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_index = torch.tensor(accuracies).argmax().item()\n",
        "best_architecture = sampled_architectures[best_index]\n",
        "\n",
        "print(\"Best Accuracy:\", accuracies[best_index])\n",
        "print(\"Best Outputs:\", best_architecture['outputs'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgsKdLkekI00",
        "outputId": "ef9e0688-2739-4ec0-c87d-d6c2dcd3de29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Accuracy: 0.7993\n",
            "Best Outputs: [5, 5, 16, 5, 5, 16, 5, 5, 16]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CN_best = ChildNetwork(outputs=best_architecture['outputs'], skip_prob=best_architecture['skip_probs'])\n",
        "optimizer = optim.Adam(CN_best.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "final_accuracy = train_test(\n",
        "    CN_best, train_images_normalized, train_labels,\n",
        "    test_images_normalized, test_labels,\n",
        "    optimizer=optimizer, criterion=criterion,\n",
        "    batch_size=32, epochs=300  # Train longer\n",
        ")\n",
        "\n",
        "print(\"Final accuracy of best architecture:\", final_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIfAhv4ZkKzl",
        "outputId": "e4fa20a3-abc6-4295-a0df-ed64c3d691a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final accuracy of best architecture: 0.9244\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iLRzWev4JIiW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}